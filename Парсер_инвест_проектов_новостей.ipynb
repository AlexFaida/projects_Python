{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mscDY-hB7ESd",
        "KBJQn-FLgcoT",
        "VbxOMVEXMHnu",
        "vCpWy2aHsFXT"
      ],
      "authorship_tag": "ABX9TyNmE1HchzVF0i83tfL+ZlL+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexFaida/projects_Python/blob/Web-scraping/%D0%9F%D0%B0%D1%80%D1%81%D0%B5%D1%80_%D0%B8%D0%BD%D0%B2%D0%B5%D1%81%D1%82_%D0%BF%D1%80%D0%BE%D0%B5%D0%BA%D1%82%D0%BE%D0%B2_%D0%BD%D0%BE%D0%B2%D0%BE%D1%81%D1%82%D0%B5%D0%B9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ссылки на используемые сайты"
      ],
      "metadata": {
        "id": "7_t7otJL7Uiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Новости:**\n",
        "- **Gazeta.uz**: [Ссылка](https://www.gazeta.uz/ru/archive)\n",
        "- **Kun.uz**: [Ссылка](https://kun.uz/ru/news/list)\n",
        "- **Sputnik Uzbekistan (Economy)**: [Ссылка](https://uz.sputniknews.ru/economy/)\n",
        "- **Dzen.ru (Uzbekistan)**: [Ссылка](https://dzen.ru/news/region/uzbekistan)\n",
        "- **BBGL.ru (Uzbekistan)**: [Ссылка](https://bbgl.ru/news?hashtag_place=%D0%A3%D0%B7%D0%B1%D0%B5%D0%BA%D0%B8%D1%81%D1%82%D0%B0%D0%BD)\n",
        "- **Uzbekistonmet.uz (Economic)**: [Ссылка](https://www.uzbekistonmet.uz/ru/lists/category/5)\n",
        "\n",
        "**Инвестирование:**\n",
        "- **Invest.gov.uz (Ready Invest Projects)**: [Ссылка](https://invest.gov.uz/ru/investor-taxonomy/ready-invest-projects/)\n",
        "- **Invest-in-uzbekistan.org (Enterprises Projects)**: [Ссылка](https://invest-in-uzbekistan.org/enterprises-projects/)"
      ],
      "metadata": {
        "id": "XsyftBTiu_Oh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Необходимые библиотеки"
      ],
      "metadata": {
        "id": "itOYJOEZN2j_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Необходимо для работы в google colab\n",
        "## Можно не устанавливать, если код запущен локально\n",
        "%%shell\n",
        "sudo apt -y update\n",
        "sudo apt install -y wget curl unzip\n",
        "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
        "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "dpkg -i google-chrome-stable_current_amd64.deb\n",
        "CHROME_DRIVER_VERSION=`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE`\n",
        "wget -N https://chromedriver.storage.googleapis.com/$CHROME_DRIVER_VERSION/chromedriver_linux64.zip -P /tmp/\n",
        "unzip -o /tmp/chromedriver_linux64.zip -d /tmp/\n",
        "chmod +x /tmp/chromedriver\n",
        "mv /tmp/chromedriver /usr/local/bin/chromedriver"
      ],
      "metadata": {
        "id": "vPI91a9cODpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#необходимые библиотеки\n",
        "!pip install selenium\n",
        "!pip install chromedriver-autoinstaller\n",
        "!pip install xlsxwriter\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import chromedriver_autoinstaller\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "import re\n",
        "from urllib.parse import quote\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "prJxPAybO7ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Блок новостей"
      ],
      "metadata": {
        "id": "rU43grZ8lHJR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запросы без указаний осуществляются по ключевым словам:\n",
        "\n",
        "*   инвест\n",
        "*   разраб\n",
        "*   строит\n",
        "*   модерн"
      ],
      "metadata": {
        "id": "4D4Gww-wuWcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kun_uz(queries):\n",
        "\n",
        "  titles, links, dates = [], [], []\n",
        "  pages = 2  # количество страниц новостей, которое необходимо спарсить. Большинство запросов запросов умещаются в 1 страницу.\n",
        "  links_of_queries = [[f' https://kun.uz/ru/news/search?q={quote(query)}&page={page}' for query in queries] for page in range(1,pages+1)]\n",
        "  links_of_queries_array = np.array(links_of_queries)\n",
        "  links_of_queries_flat = links_of_queries_array.flatten()\n",
        "\n",
        "  chrome_options = webdriver.ChromeOptions()\n",
        "  chrome_options.add_argument('--headless')\n",
        "  chrome_options.add_argument('--no-sandbox')\n",
        "  chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "  chromedriver_autoinstaller.install()\n",
        "  driver = webdriver.Chrome(options=chrome_options)\n",
        "  driver.maximize_window()\n",
        "\n",
        "  wait = WebDriverWait(driver, 10)\n",
        "\n",
        "  current_time = datetime.now()\n",
        "  current_date = current_time.strftime(\"%d.%m.%Y\")\n",
        "\n",
        "\n",
        "  for link_of_query in links_of_queries_flat:\n",
        "\n",
        "    driver.get(link_of_query)\n",
        "    wait = WebDriverWait(driver, 10)\n",
        "\n",
        "    try:\n",
        "        news_elements = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"news__title\")))\n",
        "        date_elements = wait.until(EC.presence_of_all_elements_located((By.XPATH, '//*[@id=\"news-list\"]/div/div/div')))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'Произошла ошибка с - {e} по ссылке {link_of_query}')\n",
        "\n",
        "    try:\n",
        "      for single_news in news_elements:\n",
        "\n",
        "        titles.append(single_news.text)\n",
        "        links.append(single_news.get_attribute(\"href\"))\n",
        "\n",
        "      for single_news in date_elements:\n",
        "\n",
        "        dates.append(single_news.text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'Произошла ошибка с - {e} по ссылке {link_of_query}')\n",
        "\n",
        "  driver.quit()\n",
        "\n",
        "  dates_f = []\n",
        "  try:\n",
        "    for date in dates:\n",
        "        if '/' in date:\n",
        "            date_filt = ''.join(date.split(' / ')[1])\n",
        "            dates_f.append(date_filt)\n",
        "        else:\n",
        "            dates_f.append(current_date)\n",
        "    data = {'Title': titles, 'Link': links, 'Date': dates_f}\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f'Ошибка перевода даты {e}')\n",
        "    data = {'Title': titles, 'Link': links, 'Date': dates}\n",
        "\n",
        "  df_kun_uz = pd.DataFrame(data)\n",
        "\n",
        "  return df_kun_uz\n",
        "\n",
        "\n",
        "def sputniknews(queries):\n",
        "\n",
        "  titles, links, dates = [], [], []\n",
        "\n",
        "  chrome_options = webdriver.ChromeOptions()\n",
        "  chrome_options.add_argument('--headless')\n",
        "  chrome_options.add_argument('--no-sandbox')\n",
        "  chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "  chromedriver_autoinstaller.install()\n",
        "  driver = webdriver.Chrome(options=chrome_options)\n",
        "  driver.maximize_window()\n",
        "\n",
        "  current_time = datetime.now()\n",
        "  current_year = current_time.strftime(\"%Y\")\n",
        "\n",
        "  for query in queries:\n",
        "\n",
        "      link_of_query = f'https://uz.sputniknews.ru/search/?query={query}'\n",
        "      driver.get(link_of_query)\n",
        "      wait = WebDriverWait(driver, 10)\n",
        "\n",
        "      try:\n",
        "          info_elements = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"list__content\")))\n",
        "          date_elements = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"list__date \")))\n",
        "      except Exception as e:\n",
        "          print(f'Произошла ошибка с поиском ифнормации- {e} по ссылке {link_of_query}')\n",
        "\n",
        "      try:\n",
        "        for single_news in info_elements:\n",
        "\n",
        "          link_element = single_news.find_element(By.TAG_NAME, 'a')\n",
        "          titles.append(single_news.text)\n",
        "          links.append(link_element.get_attribute(\"href\"))\n",
        "\n",
        "        for single_news_date in date_elements:\n",
        "          dates.append(single_news_date.text)\n",
        "      except Exception as e:\n",
        "          print(f'Произошла ошибка с - {e} по ссылке {link_of_query}')\n",
        "\n",
        "  driver.quit()\n",
        "\n",
        "\n",
        "  dates_f = []\n",
        "\n",
        "  for date in dates:\n",
        "      if ',' in date:\n",
        "          date_filt = ' '.join(date.split(', ')[:-1])\n",
        "          if len(date_filt.split()) == 2:\n",
        "              dates_f.append(date_filt + ' ' + current_year)\n",
        "          else:\n",
        "              dates_f.append(date_filt)\n",
        "      else:\n",
        "          dates_f.append(' ')\n",
        "\n",
        "  try:\n",
        "      if len(titles) != len(links) or len(titles) != len(dates_f):\n",
        "          raise ValueError(\"Длины заголовков, ссылок и дат должны быть равными.\")\n",
        "\n",
        "      data = {'Title': titles, 'Link': links, 'Date': dates_f}\n",
        "      df_sputniknews = pd.DataFrame(data)\n",
        "\n",
        "      return df_sputniknews\n",
        "\n",
        "  except ValueError as ve:\n",
        "      print(\"ValueError на сайте sputniknews:\", ve)\n",
        "      return None\n",
        "  except Exception as e:\n",
        "      print(\"An unexpected error на сайте sputniknews:\", e)\n",
        "      return None\n",
        "\n",
        "def gazeta_uz(queries):\n",
        "    titles, dates, links = [], [], []\n",
        "    chrome_options = webdriver.ChromeOptions()\n",
        "    chrome_options.add_argument('--headless')\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "    chromedriver_autoinstaller.install()\n",
        "    driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "    current_time = datetime.now()\n",
        "\n",
        "    for query in queries:\n",
        "        link = 'https://www.gazeta.uz/ru/search/?q=' + query\n",
        "        driver.get(link)\n",
        "        wait = WebDriverWait(driver, 10)\n",
        "\n",
        "        try:\n",
        "            info_pages = wait.until(EC.visibility_of_all_elements_located((By.CLASS_NAME, 'ut')))\n",
        "            number_of_pages = 1\n",
        "            if info_pages:\n",
        "                number_of_pages = int(info_pages[0].text.strip()[-1])\n",
        "        except Exception as e:\n",
        "            print(f\"Error retrieving number of pages for query '{query}': {str(e)}\")\n",
        "\n",
        "        for page in range(number_of_pages):\n",
        "            info = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'nblock')))\n",
        "            for news in info:\n",
        "                date, title = news.text.split('\\n')[:2]\n",
        "\n",
        "                date = date.split()[:3]\n",
        "                date_str = ' '.join(i.rstrip(',') for i in date)\n",
        "\n",
        "                if  'Сегодня' in date_str:\n",
        "                    dates.append(current_time.strftime(\"%d.%m.%Y\"))\n",
        "                elif 'Вчера' in date_str:\n",
        "                    dates.append((current_time - timedelta(days=1)).strftime(\"%d.%m.%Y\"))\n",
        "                else:\n",
        "                    dates.append(date_str)\n",
        "\n",
        "\n",
        "                titles.append(title)\n",
        "                link_element = news.find_element(By.CLASS_NAME, 'nimg')\n",
        "                link = link_element.get_attribute(\"href\")\n",
        "                links.append(link)\n",
        "\n",
        "            try:\n",
        "                see_more_button = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, 'next')))\n",
        "                see_more_button.click()\n",
        "            except Exception as e:\n",
        "                print(f\"Error clicking 'Next' button for query '{query}' on page {page + 1}: {str(e)}\")\n",
        "                break\n",
        "    driver.quit()\n",
        "\n",
        "    try:\n",
        "        if len(titles) != len(links) or len(titles) != len(dates):\n",
        "            raise ValueError(\"Длины заголовков, ссылок и дат должны быть равными.\")\n",
        "\n",
        "        data = {'Title': titles, 'Link': links, 'Date': dates}\n",
        "        df_gazeta = pd.DataFrame(data)\n",
        "\n",
        "        return df_gazeta\n",
        "\n",
        "    except ValueError as ve:\n",
        "        print(\"ValueError на сайте gazeta:\", ve)\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(\"An unexpected error на сайте gazeta:\", e)\n",
        "        return None\n",
        "def dzen():\n",
        "  titles, links, dates = [], [], []\n",
        "  chrome_options = webdriver.ChromeOptions()\n",
        "  chrome_options.add_argument('--headless')\n",
        "  chrome_options.add_argument('--no-sandbox')\n",
        "  chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "  chromedriver_autoinstaller.install()\n",
        "  driver = webdriver.Chrome(options=chrome_options)\n",
        "  driver.maximize_window()\n",
        "\n",
        "  current_time = datetime.now()\n",
        "\n",
        "  query = 'https://dzen.ru/news/region/uzbekistan'\n",
        "  driver.get(query)\n",
        "  wait = WebDriverWait(driver, 10)\n",
        "  try:\n",
        "      title_elements = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"news-card2-redesign__title\")))\n",
        "      date_elements = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"news-story-redesign__time\")))\n",
        "      link_elements = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"Link\")))\n",
        "  except Exception as e:\n",
        "      print('Произошла ошибка с ', e)\n",
        "\n",
        "  try:\n",
        "    for single_news_title in title_elements:\n",
        "\n",
        "      titles.append(single_news_title.text)\n",
        "\n",
        "    for single_news_date in date_elements:\n",
        "      if 'назад'in single_news_date.text or 'Сегодня' in single_news_date.text:\n",
        "          dates.append(current_time.strftime(\"%d.%m.%Y\"))\n",
        "      elif 'Вчера' in single_news_date.text:\n",
        "          dates.append((current_time - timedelta(days=1)).strftime(\"%d.%m.%Y\"))\n",
        "      else:\n",
        "          dates.append(f'{single_news_date.text} {current_time.strftime(\"%Y\")}')\n",
        "    for single_news_link in link_elements:\n",
        "      links.append(single_news_link.get_attribute(\"href\"))\n",
        "  except Exception as e:\n",
        "      print('Произошла ошибка с ', e)\n",
        "\n",
        "  driver.quit()\n",
        "\n",
        "  try:\n",
        "      if len(titles) != len(links) or len(titles) != len(dates):\n",
        "          raise ValueError(\"Длины заголовков, ссылок и дат должны быть равными.\")\n",
        "\n",
        "      data = {'Title': titles, 'Link': links, 'Date': dates}\n",
        "      df_dzen = pd.DataFrame(data)\n",
        "      return df_dzen\n",
        "\n",
        "  except ValueError as ve:\n",
        "      print(\"ValueError на сайте dzen:\", ve)\n",
        "      return None\n",
        "  except Exception as e:\n",
        "      print(\"An unexpected error на сайте dzen:\", e)\n",
        "      return None\n",
        "\n",
        "\n",
        "def uzbekistonmet_uz(queries):\n",
        "\n",
        "  titles, links, dates = [], [], []\n",
        "\n",
        "  for query in queries:\n",
        "      chrome_options = webdriver.ChromeOptions()\n",
        "      chrome_options.add_argument('--headless')\n",
        "      chrome_options.add_argument('--no-sandbox')\n",
        "      chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "      chromedriver_autoinstaller.install()\n",
        "      driver = webdriver.Chrome(options=chrome_options)\n",
        "      driver.maximize_window()\n",
        "\n",
        "      link = f'https://www.uzbekistonmet.uz/ru/search/index?SearchForm%5Btext%5D={query}'\n",
        "      driver.get(link)\n",
        "      wait = WebDriverWait(driver, 10)\n",
        "\n",
        "      try:\n",
        "          info_elements = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"title_link\")))\n",
        "          date_elements = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"date_time\")))\n",
        "      except Exception as e:\n",
        "          print('Произошла ошибка с ', e)\n",
        "\n",
        "      try:\n",
        "        for single_news_info in info_elements:\n",
        "          titles.append(single_news_info.text)\n",
        "          links.append(single_news_info.get_attribute(\"href\"))\n",
        "        for single_news_date in date_elements:\n",
        "          dates.append(single_news_date.text)\n",
        "      except Exception as e:\n",
        "          print('Произошла ошибка с ', e)\n",
        "\n",
        "      driver.quit()\n",
        "\n",
        "\n",
        "  titles_f, links_f, date_f = [], [], []\n",
        "\n",
        "  dates_filt = [info.split(' | ') for info in dates]\n",
        "\n",
        "  for title, link, date in zip(titles, links, dates_filt):\n",
        "    if date[1] != 'Вакансии':\n",
        "      titles_f.append(title)\n",
        "      links_f.append(link)\n",
        "      date_f.append(date[0])\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  try:\n",
        "      if len(titles) != len(links) or len(titles) != len(dates):\n",
        "          raise ValueError(\"Длины заголовков, ссылок и дат должны быть равными.\")\n",
        "\n",
        "      data_f = {'Title': titles_f, 'Link': links_f, 'Date': date_f}\n",
        "      df_uzbekistonmet_uz = pd.DataFrame(data_f)\n",
        "\n",
        "      return df_uzbekistonmet_uz\n",
        "\n",
        "  except ValueError as ve:\n",
        "      print(\"ValueError на сайте uzbekistonmet:\", ve)\n",
        "      return None\n",
        "  except Exception as e:\n",
        "      print(\"An unexpected error на сайте uzbekistonmet:\", e)\n",
        "      return None\n",
        "\n",
        "\n",
        "\n",
        "def bbgl_ru():\n",
        "\n",
        "  links_of_queries = ['https://bbgl.ru/news?hashtag_place=%D0%A3%D0%B7%D0%B1%D0%B5%D0%BA%D0%B8%D1%81%D1%82%D0%B0%D0%BD',\n",
        "          'https://bbgl.ru/obekty-stroitelstva?hashtag_place=%D0%A3%D0%B7%D0%B1%D0%B5%D0%BA%D0%B8%D1%81%D1%82%D0%B0%D0%BD']\n",
        "\n",
        "  titles, links, dates = [], [], []\n",
        "\n",
        "  chrome_options = webdriver.ChromeOptions()\n",
        "  chrome_options.add_argument('--headless')\n",
        "  chrome_options.add_argument('--no-sandbox')\n",
        "  chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "  chromedriver_autoinstaller.install()\n",
        "  driver = webdriver.Chrome(options=chrome_options)\n",
        "  driver.maximize_window()\n",
        "  wait = WebDriverWait(driver, 10)\n",
        "\n",
        "  for link in links_of_queries:\n",
        "    driver.get(link)\n",
        "\n",
        "    try:\n",
        "        date_elements = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"date\")))\n",
        "        info_elements = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"title-link\")))\n",
        "    except Exception as e:\n",
        "        print(f'Произошла ошибка с {link}', e)\n",
        "\n",
        "    try:\n",
        "      for single_news_info in info_elements:\n",
        "        titles.append(single_news_info.text)\n",
        "        links.append(single_news_info.get_attribute(\"href\"))\n",
        "\n",
        "      for single_news_info in date_elements:\n",
        "        dates.append(single_news_info.text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'Произошла ошибка с {link}', e)\n",
        "\n",
        "  driver.quit()\n",
        "\n",
        "  dates_f = [' '.join(date.split()[:3]) for date in dates]\n",
        "\n",
        "  try:\n",
        "      if len(titles) != len(links) or len(titles) != len(dates_f):\n",
        "          raise ValueError(\"Длины заголовков, ссылок и дат должны быть равными.\")\n",
        "\n",
        "      data = {'Title': titles, 'Link': links, 'Date': dates_f}\n",
        "      df_bbgl = pd.DataFrame(data)\n",
        "      return df_bbgl\n",
        "\n",
        "  except ValueError as ve:\n",
        "      print(\"ValueError на сайте bbgl.ru:\", ve)\n",
        "      return None\n",
        "  except Exception as e:\n",
        "      print(\"An unexpected error на сайте bbgl.ru:\", e)\n",
        "      return None"
      ],
      "metadata": {
        "id": "Juy_BEGClMDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_date(date_str):\n",
        "    if pd.isna(date_str):\n",
        "        return None\n",
        "    if len(date_str.split('.')) != 3:\n",
        "        parts = date_str.split()\n",
        "        if len(parts) == 3:\n",
        "            months = {\n",
        "                'января': 1,\n",
        "                'февраля': 2,\n",
        "                'марта': 3,\n",
        "                'апреля': 4,\n",
        "                'мая': 5,\n",
        "                'июня': 6,\n",
        "                'июля': 7,\n",
        "                'августа': 8,\n",
        "                'сентября': 9,\n",
        "                'октября': 10,\n",
        "                'ноября': 11,\n",
        "                'декабря': 12\n",
        "            }\n",
        "            day, month, year = parts\n",
        "            month = months.get(month.lower())\n",
        "            if month:\n",
        "                return f\"{day}.{month:02d}.{year}\"\n",
        "            else:\n",
        "                return None\n",
        "        else:\n",
        "            return None\n",
        "    else:\n",
        "        return date_str"
      ],
      "metadata": {
        "id": "fkfw0KVvq-bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def news_to_excel(start_date=None, end_date=None, queries=None):\n",
        "\n",
        "    if end_date is None:\n",
        "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
        "    if start_date is None:\n",
        "        start_date = (datetime.now() - timedelta(days=29)).strftime('%Y-%m-%d')\n",
        "    if queries is None:\n",
        "      queries = ['инвест', 'разраб', 'строит', 'модерн']\n",
        "\n",
        "    df_kun_uz = kun_uz(queries)\n",
        "    df_sputniknews = sputniknews(queries)\n",
        "    df_gazeta_uz = gazeta_uz(queries)\n",
        "    df_dzen = dzen()\n",
        "    df_uzbekistonmet_uz = uzbekistonmet_uz(queries)\n",
        "    df_bbgl = bbgl_ru()\n",
        "\n",
        "    dfs = [df_kun_uz, df_sputniknews, df_gazeta_uz, df_dzen, df_uzbekistonmet_uz, df_bbgl]\n",
        "    dfs_valid = []\n",
        "\n",
        "    for i, df in enumerate(dfs):\n",
        "        if not df.empty:\n",
        "          dfs_valid.append(df)\n",
        "        else:\n",
        "          print(f'Ошибка с сайтом - {dfs[i]}')\n",
        "\n",
        "    combined_df = pd.concat(dfs_valid, ignore_index=True)\n",
        "    combined_df['Date'] = combined_df['Date'].apply(convert_date)\n",
        "    combined_df['Date'] = pd.to_datetime(combined_df['Date'], format='%d.%m.%Y')\n",
        "\n",
        "    end_date = datetime.now()\n",
        "    start_date = end_date - timedelta(days=29)\n",
        "    news_last_days = combined_df[(combined_df['Date'] >= start_date) & (combined_df['Date'] <= end_date)]\n",
        "    news_last_days['Date'] = news_last_days['Date'].dt.strftime('%d-%m-%Y')\n",
        "    return news_last_days"
      ],
      "metadata": {
        "id": "a-gWmbn-l8wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Блок проектов"
      ],
      "metadata": {
        "id": "4GG-rn9jLbmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def invest_in_uzbekistan():\n",
        "\n",
        "  chrome_options = webdriver.ChromeOptions()\n",
        "  chrome_options.add_argument('--headless')\n",
        "  chrome_options.add_argument('--no-sandbox')\n",
        "  chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "  chromedriver_autoinstaller.install()\n",
        "  driver = webdriver.Chrome(options=chrome_options)\n",
        "  driver.maximize_window()\n",
        "  titles, links, investments = [], [], []\n",
        "  link = 'https://invest-in-uzbekistan.org/enterprises-projects/'\n",
        "  driver.get(link)\n",
        "  wait = WebDriverWait(driver, 10)\n",
        "  try:\n",
        "      price_elements = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"main-search-result-price\")))\n",
        "      title_elements = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"main-search-result-title\")))\n",
        "      link_elements = wait.until(EC.presence_of_all_elements_located((By.XPATH, '//*[@id=\"main-search-results\"]/div/div/div/div[1]/a')))\n",
        "\n",
        "  except Exception as e:\n",
        "      print('Произошла ошибка с ', e)\n",
        "\n",
        "  try:\n",
        "\n",
        "    for price, title, link in zip(price_elements, title_elements, link_elements):\n",
        "      titles.append(title.text)\n",
        "      links.append(link.get_attribute(\"href\"))\n",
        "\n",
        "      invest_str = ''.join(filter(str.isdigit,(price.text.split(': ')[1])))\n",
        "\n",
        "      if invest_str:\n",
        "        investments.append(int(invest_str))\n",
        "\n",
        "      else:\n",
        "        investments.append(0)\n",
        "\n",
        "\n",
        "  except Exception as e:\n",
        "      print('Произошла ошибка с ', e)\n",
        "  driver.quit()\n",
        "\n",
        "\n",
        "  try:\n",
        "      if len(titles) != len(links) or len(titles) != len(investments):\n",
        "          raise ValueError(\"Длины заголовков, ссылок и дат должны быть равными.\")\n",
        "\n",
        "      data = {'Title': titles, 'Link': links, 'Investments ($)': investments}\n",
        "      df_invest_in_uzbekistan = pd.DataFrame(data)\n",
        "      return df_invest_in_uzbekistan\n",
        "\n",
        "  except ValueError as ve:\n",
        "      print(\"ValueError на сайте invest_in_uzbekistan:\", ve)\n",
        "      return None\n",
        "  except Exception as e:\n",
        "      print(\"An unexpected error на сайте invest_in_uzbekistan:\", e)\n",
        "      return None\n",
        "\n",
        "def invest_gov_uz():\n",
        "\n",
        "  titles, links, investments = [], [], []\n",
        "  chrome_options = webdriver.ChromeOptions()\n",
        "  chrome_options.add_argument('--headless')\n",
        "  chrome_options.add_argument('--no-sandbox')\n",
        "  chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "  chromedriver_autoinstaller.install()\n",
        "  driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "\n",
        "  link = 'https://invest.gov.uz/ru/investor-taxonomy/ready-invest-projects/'\n",
        "  driver.get(link)\n",
        "\n",
        "  wait = WebDriverWait(driver, 10)\n",
        "\n",
        "  try:\n",
        "\n",
        "      info = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'content-item-title')))\n",
        "      invest_info = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'content-item-price')))\n",
        "\n",
        "  except Exception as e:\n",
        "\n",
        "      print(f\"Ошибка извлечения информации {str(e)}\")\n",
        "  try:\n",
        "    for single_news in info:\n",
        "      link_element = single_news.find_element(By.TAG_NAME, 'a')\n",
        "      titles.append(single_news.text)\n",
        "      links.append(link_element.get_attribute(\"href\"))\n",
        "\n",
        "    for single_inv in invest_info:\n",
        "\n",
        "      invest_str = ''.join(filter(str.isdigit, single_inv.text))\n",
        "      if invest_str:\n",
        "        investments.append(int(invest_str))\n",
        "      else:\n",
        "        investments.append(0)\n",
        "\n",
        "  except Exception as e:\n",
        "    print('Ошибка - ', e)\n",
        "  driver.quit()\n",
        "\n",
        "  try:\n",
        "      if len(titles) != len(links) or len(titles) != len(investments):\n",
        "          raise ValueError(\"Длины заголовков, ссылок и дат должны быть равными.\")\n",
        "\n",
        "      data = {'Title': titles, 'Link': links, 'Investments ($)': investments}\n",
        "      df_invest_qov_uz = pd.DataFrame(data)\n",
        "      return df_invest_qov_uz\n",
        "\n",
        "  except ValueError as ve:\n",
        "      print(\"ValueError на сайте invest_gov_uz:\", ve)\n",
        "      return None\n",
        "  except Exception as e:\n",
        "      print(\"An unexpected error на сайте invest_gov_uz:\", e)\n",
        "      return None"
      ],
      "metadata": {
        "id": "9Muo1AEUnpyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inv_projects_to_excel():\n",
        "\n",
        "\n",
        "    df_invest_qov_uz = invest_gov_uz()\n",
        "    df_invest_in_uzbekistan = invest_in_uzbekistan()\n",
        "\n",
        "\n",
        "    dfs = [df_invest_qov_uz, df_invest_in_uzbekistan]\n",
        "    dfs_valid = []\n",
        "\n",
        "    for i, df in enumerate(dfs):\n",
        "        if not df.empty:\n",
        "          dfs_valid.append(df)\n",
        "        else:\n",
        "          print(f'Ошибка с сайтом - {dfs[i]}')\n",
        "\n",
        "    df_inv = pd.concat(dfs_valid, ignore_index=True)\n",
        "\n",
        "    return df_inv"
      ],
      "metadata": {
        "id": "mnrSh7-noJA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вывод общей excel таблицы"
      ],
      "metadata": {
        "id": "nYtiahOIJRTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with pd.ExcelWriter(f\"news_inv_projects_{datetime.now().strftime('%B_%Y')}.xlsx\", engine='xlsxwriter') as writer:\n",
        "    news_to_excel().to_excel(writer, sheet_name=f'news', index=False)\n",
        "    inv_projects_to_excel().to_excel(writer, sheet_name='invest_projects', index=False)"
      ],
      "metadata": {
        "id": "gvb0GZ-mRfFn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}